{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Trading Risk Management System - Complete Usage Example\n",
    "\n",
    "This notebook demonstrates the complete workflow of the Trading Risk Management System, from data ingestion to risk prediction and monitoring."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "\n",
    "# System imports\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path('..').resolve()))\n",
    "\n",
    "# Project imports\n",
    "from src.data.database_manager import DatabaseManager\n",
    "from src.data.data_downloader import DataDownloader\n",
    "from src.pipeline.data_validator import DataValidator\n",
    "from src.pipeline.feature_pipeline import FeaturePipeline\n",
    "from src.pipeline.model_pipeline import ModelPipeline\n",
    "from src.features.technical_features import TechnicalFeatures\n",
    "from src.features.behavioral_features import BehavioralFeatures\n",
    "from src.features.market_regime_features import MarketRegimeFeatures\n",
    "from src.models.risk_model import RiskModel\n",
    "from src.utils.time_series_cv import TimeSeriesSplit, WalkForwardAnalysis\n",
    "from src.backtesting.backtest_engine import BacktestEngine, OrderType, Order\n",
    "from src.backtesting.performance_metrics import PerformanceMetrics\n",
    "from src.monitoring.model_monitor import ModelMonitor\n",
    "from src.monitoring.drift_detector import DriftDetector\n",
    "from src.monitoring.alert_system import AlertSystem\n",
    "from src.monitoring.dashboard_generator import DashboardGenerator\n",
    "from src.core.constants import TradingConstants as TC\n",
    "\n",
    "print(\"All imports successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## 2. Initialize System Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize core components\n",
    "db = Database()\n",
    "validator = DataValidator()\n",
    "feature_pipeline = FeaturePipeline()\n",
    "model_pipeline = ModelPipeline()\n",
    "perf_metrics = PerformanceMetrics()\n",
    "\n",
    "# Check database status\n",
    "stats = db.get_database_stats()\n",
    "print(\"Database Statistics:\")\n",
    "for key, value in stats.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 3. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of traders\n",
    "traders = db.get_all_traders()\n",
    "print(f\"Total traders: {len(traders)}\")\n",
    "print(\"\\nTop 10 traders by total P&L:\")\n",
    "traders.sort_values('total_pnl', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a trader for detailed analysis\n",
    "example_trader = traders.iloc[0]\n",
    "account_id = example_trader['account_id']\n",
    "trader_name = example_trader['trader_name']\n",
    "\n",
    "print(f\"Analyzing trader: {trader_name} (ID: {account_id})\")\n",
    "\n",
    "# Get trader data\n",
    "totals_df, fills_df = db.get_trader_data(account_id)\n",
    "\n",
    "print(f\"\\nData summary:\")\n",
    "print(f\"  Daily totals: {len(totals_df)} days\")\n",
    "print(f\"  Fills: {len(fills_df)} trades\")\n",
    "print(f\"  Date range: {totals_df['date'].min()} to {totals_df['date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize P&L history\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Cumulative P&L\n",
    "cumulative_pnl = totals_df['net_pnl'].cumsum()\n",
    "axes[0, 0].plot(totals_df['date'], cumulative_pnl)\n",
    "axes[0, 0].set_title('Cumulative P&L')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Cumulative P&L')\n",
    "\n",
    "# Daily P&L distribution\n",
    "axes[0, 1].hist(totals_df['net_pnl'], bins=50, edgecolor='black')\n",
    "axes[0, 1].set_title('Daily P&L Distribution')\n",
    "axes[0, 1].set_xlabel('Daily P&L')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Rolling volatility\n",
    "rolling_vol = totals_df['net_pnl'].rolling(20).std()\n",
    "axes[1, 0].plot(totals_df['date'], rolling_vol)\n",
    "axes[1, 0].set_title('20-Day Rolling Volatility')\n",
    "axes[1, 0].set_xlabel('Date')\n",
    "axes[1, 0].set_ylabel('Volatility')\n",
    "\n",
    "# Drawdown\n",
    "cumsum = totals_df['net_pnl'].cumsum()\n",
    "running_max = cumsum.expanding().max()\n",
    "drawdown = (cumsum - running_max) / running_max\n",
    "axes[1, 1].fill_between(totals_df['date'], drawdown * 100, 0, alpha=0.3, color='red')\n",
    "axes[1, 1].set_title('Drawdown %')\n",
    "axes[1, 1].set_xlabel('Date')\n",
    "axes[1, 1].set_ylabel('Drawdown %')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate key metrics\n",
    "returns = totals_df['net_pnl'].values\n",
    "metrics = perf_metrics.calculate_metrics(returns)\n",
    "print(\"\\nKey Performance Metrics:\")\n",
    "for metric, value in list(metrics.items())[:10]:\n",
    "    print(f\"  {metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## 4. Data Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate data quality\n",
    "validation_result = validator.validate_combined(totals_df, fills_df)\n",
    "\n",
    "print(f\"Validation Status: {'PASSED' if validation_result.is_valid else 'FAILED'}\")\n",
    "\n",
    "if validation_result.errors:\n",
    "    print(\"\\nErrors:\")\n",
    "    for error in validation_result.errors:\n",
    "        print(f\"  - {error}\")\n",
    "\n",
    "if validation_result.warnings:\n",
    "    print(\"\\nWarnings:\")\n",
    "    for warning in validation_result.warnings[:5]:  # Show first 5\n",
    "        print(f\"  - {warning}\")\n",
    "\n",
    "# Print validation report\n",
    "print(\"\\n\" + validator.generate_report(validation_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate features\n",
    "print(\"Generating features...\")\n",
    "features_df = feature_pipeline.generate_features(totals_df, fills_df)\n",
    "\n",
    "print(f\"\\nFeatures generated: {features_df.shape[1]} features for {len(features_df)} samples\")\n",
    "print(f\"\\nFeature categories:\")\n",
    "\n",
    "# Count features by category\n",
    "feature_categories = {}\n",
    "for col in features_df.columns:\n",
    "    if col not in ['date', 'account_id']:\n",
    "        category = col.split('_')[0]\n",
    "        feature_categories[category] = feature_categories.get(category, 0) + 1\n",
    "\n",
    "for cat, count in sorted(feature_categories.items()):\n",
    "    print(f\"  {cat}: {count} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore feature correlations\n",
    "numeric_features = features_df.select_dtypes(include=[np.number]).columns\n",
    "if len(numeric_features) > 20:\n",
    "    # Select top features for visualization\n",
    "    feature_subset = numeric_features[:20]\n",
    "else:\n",
    "    feature_subset = numeric_features\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "correlation_matrix = features_df[feature_subset].corr()\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix (Top 20 Features)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 6. Model Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "# Create target (next day's P&L)\n",
    "modeling_df = features_df.copy()\n",
    "modeling_df['target'] = totals_df['net_pnl'].shift(-1)\n",
    "modeling_df = modeling_df.dropna(subset=['target'])\n",
    "\n",
    "# Split features and target\n",
    "feature_cols = [col for col in modeling_df.columns \n",
    "                if col not in ['date', 'account_id', 'target']]\n",
    "X = modeling_df[feature_cols]\n",
    "y = modeling_df['target']\n",
    "\n",
    "# Add date index for time series CV\n",
    "X.index = pd.to_datetime(modeling_df['date']) if 'date' in modeling_df else modeling_df.index\n",
    "y.index = X.index\n",
    "\n",
    "print(f\"Modeling data shape: {X.shape}\")\n",
    "print(f\"Target statistics: mean={y.mean():.2f}, std={y.std():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple risk model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Simple train/test split (for demonstration)\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# Create and train model\n",
    "risk_model = RiskModel(model_name=\"example_risk_model\")\n",
    "risk_model.fit(X_train, y_train, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate\n",
    "train_score = risk_model.score(X_train, y_train)\n",
    "test_score = risk_model.score(X_test, y_test)\n",
    "\n",
    "print(f\"\\nModel Performance:\")\n",
    "print(f\"  Train R²: {train_score:.4f}\")\n",
    "print(f\"  Test R²: {test_score:.4f}\")\n",
    "\n",
    "# Get feature importance\n",
    "importance_df = risk_model.get_feature_importance(top_k=15)\n",
    "print(\"\\nTop 15 Features:\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions and calculate risk scores\n",
    "risk_predictions = risk_model.predict_risk(X_test)\n",
    "\n",
    "# Visualize predictions vs actual\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Prediction vs Actual\n",
    "axes[0].scatter(y_test, risk_predictions['predicted_pnl'], alpha=0.5)\n",
    "axes[0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "axes[0].set_xlabel('Actual P&L')\n",
    "axes[0].set_ylabel('Predicted P&L')\n",
    "axes[0].set_title('Predictions vs Actual')\n",
    "\n",
    "# Risk score distribution\n",
    "axes[1].hist(risk_predictions['risk_score'], bins=30, edgecolor='black')\n",
    "axes[1].axvline(TC.HIGH_RISK_SCORE, color='red', linestyle='--', label='High Risk Threshold')\n",
    "axes[1].set_xlabel('Risk Score')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Risk Score Distribution')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Risk analysis\n",
    "high_risk_days = risk_predictions[risk_predictions['risk_score'] > TC.HIGH_RISK_SCORE]\n",
    "print(f\"\\nHigh risk days: {len(high_risk_days)} ({len(high_risk_days)/len(risk_predictions)*100:.1f}%)\")\n",
    "\n",
    "# Check if high risk predictions were accurate\n",
    "if len(high_risk_days) > 0:\n",
    "    actual_losses = y_test[high_risk_days.index] < 0\n",
    "    print(f\"Accuracy on high risk days: {actual_losses.mean():.2%} were actual losses\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 7. Time Series Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate time series cross-validation\n",
    "ts_cv = TimeSeriesSplit(n_splits=3, mode='expanding')\n",
    "\n",
    "cv_scores = []\n",
    "for fold_idx, fold in enumerate(ts_cv.split(X)):\n",
    "    X_train_cv = X.iloc[fold.train_idx]\n",
    "    X_val_cv = X.iloc[fold.val_idx]\n",
    "    y_train_cv = y.iloc[fold.train_idx]\n",
    "    y_val_cv = y.iloc[fold.val_idx]\n",
    "    \n",
    "    # Train model\n",
    "    fold_model = RiskModel(model_name=f\"cv_fold_{fold_idx}\")\n",
    "    fold_model.fit(X_train_cv, y_train_cv)\n",
    "    \n",
    "    # Evaluate\n",
    "    val_score = fold_model.score(X_val_cv, y_val_cv)\n",
    "    cv_scores.append(val_score)\n",
    "    \n",
    "    print(f\"Fold {fold_idx}: Train samples={len(X_train_cv)}, Val samples={len(X_val_cv)}, Val R²={val_score:.4f}\")\n",
    "\n",
    "print(f\"\\nAverage CV Score: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 8. Backtesting Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple backtesting strategy based on risk predictions\n",
    "def risk_based_strategy(data_slice):\n",
    "    \"\"\"Generate trading signals based on risk predictions\"\"\"\n",
    "    orders = []\n",
    "    \n",
    "    # This is a placeholder - in reality, you'd use the model predictions\n",
    "    for _, row in data_slice.iterrows():\n",
    "        # Simple mean reversion strategy\n",
    "        if 'net_pnl' in row:\n",
    "            if row['net_pnl'] < -100:  # Buy after losses\n",
    "                orders.append(Order(\n",
    "                    timestamp=row.name,\n",
    "                    symbol='SPY',\n",
    "                    quantity=100,\n",
    "                    order_type=OrderType.MARKET\n",
    "                ))\n",
    "            elif row['net_pnl'] > 100:  # Sell after gains\n",
    "                orders.append(Order(\n",
    "                    timestamp=row.name,\n",
    "                    symbol='SPY',\n",
    "                    quantity=-100,\n",
    "                    order_type=OrderType.MARKET\n",
    "                ))\n",
    "    \n",
    "    return orders\n",
    "\n",
    "# Run backtest\n",
    "backtest_engine = BacktestEngine(initial_capital=100000)\n",
    "\n",
    "# Prepare backtest data\n",
    "backtest_data = totals_df.copy()\n",
    "backtest_data['symbol'] = 'SPY'\n",
    "backtest_data['price'] = 100 + backtest_data['net_pnl'].cumsum() / 100  # Synthetic prices\n",
    "\n",
    "# Run backtest\n",
    "results = backtest_engine.run_backtest(\n",
    "    data=backtest_data,\n",
    "    signal_func=risk_based_strategy\n",
    ")\n",
    "\n",
    "print(\"Backtest Results:\")\n",
    "print(f\"  Total Return: {results.total_return:.2%}\")\n",
    "print(f\"  Annual Return: {results.annual_return:.2%}\")\n",
    "print(f\"  Sharpe Ratio: {results.sharpe_ratio:.2f}\")\n",
    "print(f\"  Max Drawdown: {results.max_drawdown:.2%}\")\n",
    "print(f\"  Win Rate: {results.win_rate:.2%}\")\n",
    "print(f\"  Number of Trades: {results.n_trades}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## 9. Model Monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize monitoring components\n",
    "model_monitor = ModelMonitor(model_name=\"example_risk_model\")\n",
    "drift_detector = DriftDetector()\n",
    "alert_system = AlertSystem()\n",
    "\n",
    "# Set baseline for drift detection\n",
    "drift_detector.set_reference(X_train)\n",
    "\n",
    "# Simulate monitoring over time\n",
    "print(\"Simulating model monitoring...\")\n",
    "\n",
    "# Log predictions\n",
    "model_monitor.log_predictions(\n",
    "    predictions=risk_predictions,\n",
    "    actuals=y_test,\n",
    "    features=X_test,\n",
    "    prediction_time_ms=50\n",
    ")\n",
    "\n",
    "# Check for drift\n",
    "drift_results = drift_detector.detect_drift(\n",
    "    current_data=X_test,\n",
    "    features=feature_cols[:10]  # Check top 10 features\n",
    ")\n",
    "\n",
    "# Print drift results\n",
    "drifted_features = [name for name, result in drift_results.items() if result.is_drifted]\n",
    "print(f\"\\nDrift Detection Results:\")\n",
    "print(f\"  Features checked: {len(drift_results)}\")\n",
    "print(f\"  Features with drift: {len(drifted_features)}\")\n",
    "\n",
    "if drifted_features:\n",
    "    print(\"\\nDrifted features:\")\n",
    "    for feat in drifted_features[:5]:\n",
    "        result = drift_results[feat]\n",
    "        print(f\"  - {feat}: score={result.drift_score:.3f}, type={result.drift_type}\")\n",
    "\n",
    "# Check alerts\n",
    "alert_metrics = {\n",
    "    'rmse': 0.03,\n",
    "    'accuracy': 0.65,\n",
    "    'drift_rate': len(drifted_features) / len(drift_results) if drift_results else 0,\n",
    "    'n_drifted': len(drifted_features),\n",
    "    'drifted_features': drifted_features\n",
    "}\n",
    "\n",
    "triggered_alerts = alert_system.check_alerts(alert_metrics, source='monitoring')\n",
    "print(f\"\\nAlerts triggered: {len(triggered_alerts)}\")\n",
    "for alert in triggered_alerts:\n",
    "    print(f\"  [{alert.severity.value}] {alert.title}: {alert.message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## 10. Generate Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate monitoring dashboard\n",
    "dashboard_gen = DashboardGenerator()\n",
    "\n",
    "# Prepare data for dashboard\n",
    "# Get feature importance\n",
    "feature_importance = dict(zip(\n",
    "    importance_df['feature'].values,\n",
    "    importance_df['importance'].values\n",
    "))\n",
    "\n",
    "# Create monitoring metrics\n",
    "monitoring_metrics = {\n",
    "    'accuracy_history': [0.6, 0.62, 0.65, 0.63, 0.64],  # Example data\n",
    "    'summary': model_monitor.get_monitoring_summary()\n",
    "}\n",
    "\n",
    "# Generate dashboard\n",
    "dashboard_path = dashboard_gen.create_risk_dashboard(\n",
    "    predictions=risk_predictions,\n",
    "    historical_performance=totals_df,\n",
    "    feature_importance=feature_importance,\n",
    "    monitoring_metrics=monitoring_metrics,\n",
    "    drift_results=drift_results\n",
    ")\n",
    "\n",
    "print(f\"\\nDashboard generated: {dashboard_path}\")\n",
    "print(\"Open this file in your browser to view the interactive dashboard.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "## 11. Complete Pipeline Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of running the complete pipeline for multiple traders\n",
    "def analyze_all_traders(db, limit=5):\n",
    "    \"\"\"Analyze multiple traders and generate risk report\"\"\"\n",
    "    \n",
    "    traders = db.get_all_traders().head(limit)\n",
    "    risk_assessments = []\n",
    "    \n",
    "    for _, trader in traders.iterrows():\n",
    "        try:\n",
    "            # Get data\n",
    "            totals, fills = db.get_trader_data(trader['account_id'])\n",
    "            \n",
    "            if len(totals) < 50:\n",
    "                continue\n",
    "            \n",
    "            # Validate\n",
    "            validation = validator.validate_totals(totals)\n",
    "            if not validation.is_valid:\n",
    "                continue\n",
    "            \n",
    "            # Generate features\n",
    "            features = feature_pipeline.generate_features(totals, fills)\n",
    "            \n",
    "            # Get latest features for prediction\n",
    "            latest_features = features.iloc[-1:]\n",
    "            \n",
    "            # Assess risk (using simple heuristics for demo)\n",
    "            recent_volatility = totals['net_pnl'].tail(20).std()\n",
    "            recent_return = totals['net_pnl'].tail(20).mean()\n",
    "            \n",
    "            risk_assessments.append({\n",
    "                'trader_id': trader['account_id'],\n",
    "                'trader_name': trader['trader_name'],\n",
    "                'total_pnl': trader['total_pnl'],\n",
    "                'recent_volatility': recent_volatility,\n",
    "                'recent_return': recent_return,\n",
    "                'risk_score': recent_volatility / (abs(recent_return) + 1),\n",
    "                'recommendation': 'Monitor' if recent_volatility > 100 else 'Normal'\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing {trader['trader_name']}: {e}\")\n",
    "    \n",
    "    return pd.DataFrame(risk_assessments)\n",
    "\n",
    "# Run analysis\n",
    "print(\"Analyzing multiple traders...\")\n",
    "risk_report = analyze_all_traders(db, limit=5)\n",
    "\n",
    "if not risk_report.empty:\n",
    "    print(\"\\nRisk Assessment Report:\")\n",
    "    print(risk_report.sort_values('risk_score', ascending=False))\n",
    "else:\n",
    "    print(\"No traders analyzed successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## 12. Summary and Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"TRADING RISK MANAGEMENT SYSTEM - SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nThis notebook demonstrated the complete workflow:\")\n",
    "print(\"\\n1. Data Ingestion and Storage\")\n",
    "print(\"   - Database setup and data retrieval\")\n",
    "print(\"   - Support for multiple traders\")\n",
    "print(\"\\n2. Data Validation\")\n",
    "print(\"   - Comprehensive quality checks\")\n",
    "print(\"   - Trading-specific validations\")\n",
    "print(\"\\n3. Feature Engineering\")\n",
    "print(\"   - Technical indicators\")\n",
    "print(\"   - Behavioral features\")\n",
    "print(\"   - Market regime features\")\n",
    "print(\"\\n4. Model Training\")\n",
    "print(\"   - LightGBM risk models\")\n",
    "print(\"   - Time series cross-validation\")\n",
    "print(\"   - Feature importance analysis\")\n",
    "print(\"\\n5. Risk Prediction\")\n",
    "print(\"   - Daily P&L prediction\")\n",
    "print(\"   - Risk score calculation\")\n",
    "print(\"   - Confidence estimation\")\n",
    "print(\"\\n6. Backtesting\")\n",
    "print(\"   - Strategy simulation\")\n",
    "print(\"   - Performance metrics\")\n",
    "print(\"\\n7. Monitoring\")\n",
    "print(\"   - Model performance tracking\")\n",
    "print(\"   - Data drift detection\")\n",
    "print(\"   - Automated alerting\")\n",
    "print(\"\\n8. Reporting\")\n",
    "print(\"   - Interactive dashboards\")\n",
    "print(\"   - Risk reports\")\n",
    "print(\"\\nNext Steps:\")\n",
    "print(\"1. Run scripts/setup_database.py to download all historical data\")\n",
    "print(\"2. Run scripts/train_models.py to train production models\")\n",
    "print(\"3. Run scripts/daily_predict.py for daily risk predictions\")\n",
    "print(\"4. Monitor model performance and retrain as needed\")\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk-tool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
