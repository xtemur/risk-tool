{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "Risk Management System - Debug & Test Notebook\n",
    "Use this notebook to test each component individually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from datetime import date, timedelta\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(\"src\")\n",
    "sys.path.append(\".\")\n",
    "\n",
    "print(\"=== RISK MANAGEMENT SYSTEM DEBUG NOTEBOOK ===\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Environment & Configuration Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_environment():\n",
    "    \"\"\"Test environment setup and configuration loading\"\"\"\n",
    "    print(\"\\n=== TESTING ENVIRONMENT ===\")\n",
    "\n",
    "    # Test .env file loading\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    # Check required environment variables\n",
    "    required_vars = [\"EMAIL_FROM\", \"EMAIL_PASSWORD\", \"API_TOKEN\"]\n",
    "    env_status = {}\n",
    "\n",
    "    for var in required_vars:\n",
    "        value = os.getenv(var)\n",
    "        env_status[var] = \"âœ… SET\" if value else \"âŒ MISSING\"\n",
    "        if value:\n",
    "            # Mask sensitive data for display\n",
    "            masked = (\n",
    "                value[:4] + \"*\" * (len(value) - 8) + value[-4:]\n",
    "                if len(value) > 8\n",
    "                else \"****\"\n",
    "            )\n",
    "            print(f\"{var}: {env_status[var]} ({masked})\")\n",
    "        else:\n",
    "            print(f\"{var}: {env_status[var]}\")\n",
    "\n",
    "    # Test config file loading\n",
    "    try:\n",
    "        with open(\"config/config.yaml\", \"r\") as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        print(\"âœ… Main config loaded successfully\")\n",
    "\n",
    "        with open(\"config/trader_accounts.yaml\", \"r\") as f:\n",
    "            traders = yaml.safe_load(f)\n",
    "        print(f\"âœ… Trader accounts loaded: {len(traders['traders'])} traders\")\n",
    "\n",
    "        return True, config, traders\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Config loading failed: {e}\")\n",
    "        return False, None, None\n",
    "\n",
    "\n",
    "# Run environment test\n",
    "env_ok, config, traders = test_environment()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Validation Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data_loading():\n",
    "    \"\"\"Test data loading and basic validation\"\"\"\n",
    "    print(\"\\n=== TESTING DATA LOADING ===\")\n",
    "\n",
    "    try:\n",
    "        from data_loader import DataLoader\n",
    "\n",
    "        data_loader = DataLoader()\n",
    "\n",
    "        # Test loading all trader data\n",
    "        all_data = data_loader.load_all_traders_data()\n",
    "\n",
    "        if not all_data:\n",
    "            print(\"âŒ No trader data loaded\")\n",
    "            return False, None, None\n",
    "\n",
    "        print(f\"âœ… Loaded data for {len(all_data)} traders\")\n",
    "\n",
    "        # Validate data for each trader\n",
    "        for account_id, trader_data in all_data.items():\n",
    "            totals_df = trader_data[\"totals\"]\n",
    "            fills_df = trader_data[\"fills\"]\n",
    "            trader_name = trader_data[\"name\"]\n",
    "\n",
    "            print(f\"\\nðŸ“Š {trader_name} ({account_id}):\")\n",
    "            print(\n",
    "                f\"   Totals: {len(totals_df)} days, Date range: {totals_df['date'].min()} to {totals_df['date'].max()}\"\n",
    "            )\n",
    "            print(f\"   Fills: {len(fills_df)} transactions\")\n",
    "            print(f\"   Total P&L: ${totals_df['net_pnl'].sum():,.2f}\")\n",
    "\n",
    "            # Data quality checks\n",
    "            missing_dates = totals_df[\"date\"].isnull().sum()\n",
    "            missing_pnl = totals_df[\"net_pnl\"].isnull().sum()\n",
    "\n",
    "            if missing_dates > 0:\n",
    "                print(f\"   âš ï¸ Missing dates: {missing_dates}\")\n",
    "            if missing_pnl > 0:\n",
    "                print(f\"   âš ï¸ Missing P&L values: {missing_pnl}\")\n",
    "\n",
    "        # Create master dataset\n",
    "        master_totals, master_fills = data_loader.create_master_dataset(all_data)\n",
    "        print(f\"\\nâœ… Master dataset created:\")\n",
    "        print(\n",
    "            f\"   Total records: {len(master_totals)} daily records, {len(master_fills)} fills\"\n",
    "        )\n",
    "\n",
    "        return True, all_data, (master_totals, master_fills)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Data loading failed: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "        return False, None, None\n",
    "\n",
    "\n",
    "# Run data loading test\n",
    "data_ok, all_data, master_data = test_data_loading()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_feature_engineering():\n",
    "    \"\"\"Test feature engineering pipeline\"\"\"\n",
    "    print(\"\\n=== TESTING FEATURE ENGINEERING ===\")\n",
    "\n",
    "    if not data_ok or master_data is None:\n",
    "        print(\"âŒ Cannot test features - data loading failed\")\n",
    "        return False, None\n",
    "\n",
    "    try:\n",
    "        from simple_feature_engineer import SimpleFeatureEngineer\n",
    "\n",
    "        feature_engineer = SimpleFeatureEngineer()\n",
    "\n",
    "        master_totals, master_fills = master_data\n",
    "\n",
    "        # Engineer features\n",
    "        features_df = feature_engineer.engineer_features(master_totals, master_fills)\n",
    "        feature_columns = feature_engineer.get_feature_columns()\n",
    "\n",
    "        print(f\"âœ… Features engineered successfully\")\n",
    "        print(f\"   Shape: {features_df.shape}\")\n",
    "        print(f\"   Feature count: {len(feature_columns)}\")\n",
    "        print(\n",
    "            f\"   Target distribution: {features_df['target'].value_counts().to_dict()}\"\n",
    "        )\n",
    "\n",
    "        # Check for missing values\n",
    "        missing_features = features_df[feature_columns].isnull().sum()\n",
    "        if missing_features.sum() > 0:\n",
    "            print(f\"âš ï¸ Features with missing values:\")\n",
    "            for feat, count in missing_features[missing_features > 0].items():\n",
    "                print(f\"     {feat}: {count} missing\")\n",
    "        else:\n",
    "            print(\"âœ… No missing values in features\")\n",
    "\n",
    "        # Feature statistics\n",
    "        print(f\"\\nðŸ“ˆ Feature Categories:\")\n",
    "        behavioral = [\n",
    "            \"trading_frequency\",\n",
    "            \"hour_concentration\",\n",
    "            \"symbol_diversity\",\n",
    "            \"size_inconsistency\",\n",
    "            \"morning_bias\",\n",
    "        ]\n",
    "        print(\n",
    "            f\"   Behavioral signals: {[f for f in feature_columns if f in behavioral]}\"\n",
    "        )\n",
    "\n",
    "        essential = [\n",
    "            \"net_pnl\",\n",
    "            \"gross_pnl\",\n",
    "            \"total_fees\",\n",
    "            \"fee_ratio\",\n",
    "            \"qty\",\n",
    "            \"orders_count\",\n",
    "            \"avg_fill_size\",\n",
    "            \"net_pnl_5d_avg\",\n",
    "            \"cum_win_rate\",\n",
    "            \"momentum_3d\",\n",
    "        ]\n",
    "        print(f\"   Essential metrics: {[f for f in feature_columns if f in essential]}\")\n",
    "\n",
    "        temporal = [\"day_of_week\", \"is_monday\", \"is_friday\"]\n",
    "        print(f\"   Temporal features: {[f for f in feature_columns if f in temporal]}\")\n",
    "\n",
    "        return True, features_df, feature_columns\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Feature engineering failed: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "        return False, None, None\n",
    "\n",
    "\n",
    "# Run feature engineering test\n",
    "features_ok, features_df, feature_columns = test_feature_engineering()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 4. Model Training & Validation Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model_training():\n",
    "    \"\"\"Test model training with proper validation\"\"\"\n",
    "    print(\"\\n=== TESTING MODEL TRAINING ===\")\n",
    "\n",
    "    if not features_ok or features_df is None:\n",
    "        print(\"âŒ Cannot test models - feature engineering failed\")\n",
    "        return False, None\n",
    "\n",
    "    try:\n",
    "        from model_trainer import ModelTrainer\n",
    "\n",
    "        model_trainer = ModelTrainer()\n",
    "\n",
    "        # Create time-based splits for validation\n",
    "        train_df, val_df, test_df = model_trainer.create_time_splits(features_df)\n",
    "\n",
    "        print(f\"âœ… Data splits created:\")\n",
    "        print(\n",
    "            f\"   Train: {len(train_df)} samples ({len(train_df['account_id'].unique())} traders)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   Validation: {len(val_df)} samples ({len(val_df['account_id'].unique())} traders)\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   Test: {len(test_df)} samples ({len(test_df['account_id'].unique())} traders)\"\n",
    "        )\n",
    "\n",
    "        # Train global model\n",
    "        print(\"\\nðŸ”„ Training global model...\")\n",
    "        global_model = model_trainer.train_global_model(\n",
    "            train_df, val_df, feature_columns\n",
    "        )\n",
    "        print(\"âœ… Global model trained\")\n",
    "\n",
    "        # Train personal models\n",
    "        print(\"\\nðŸ”„ Training personal models...\")\n",
    "        personal_models = model_trainer.train_personal_models(\n",
    "            train_df, val_df, feature_columns\n",
    "        )\n",
    "        print(f\"âœ… Personal models trained: {len(personal_models)} models\")\n",
    "\n",
    "        # Train ARIMA baseline\n",
    "        print(\"\\nðŸ”„ Training ARIMA baseline...\")\n",
    "        arima_models = model_trainer.train_arima_baseline(train_df, val_df)\n",
    "        print(f\"âœ… ARIMA models trained: {len(arima_models)} models\")\n",
    "\n",
    "        # Evaluate all models\n",
    "        print(\"\\nðŸ“Š Evaluating models...\")\n",
    "        results = model_trainer.evaluate_models(\n",
    "            test_df, global_model, personal_models, arima_models, feature_columns\n",
    "        )\n",
    "\n",
    "        print(f\"âœ… Model evaluation completed:\")\n",
    "        print(\n",
    "            f\"   Global Model - RMSE: {results['global']['rmse']:.4f}, MAE: {results['global']['mae']:.4f}, R2: {results['global']['r2']:.4f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   Personal Models - RMSE: {results['personal']['rmse_mean']:.4f}, MAE: {results['personal']['mae_mean']:.4f}, R2: {results['personal']['r2_mean']:.4f}\"\n",
    "        )\n",
    "        print(\n",
    "            f\"   ARIMA Baseline - RMSE: {results['arima']['rmse_mean']:.4f}, MAE: {results['arima']['mae_mean']:.4f}, R2: {results['arima']['r2_mean']:.4f}\"\n",
    "        )\n",
    "\n",
    "        # Save model metadata\n",
    "        model_trainer.save_model_metadata(feature_columns, results)\n",
    "        print(\"âœ… Model metadata saved\")\n",
    "\n",
    "        return True, results\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Model training failed: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "        return False, None\n",
    "\n",
    "\n",
    "# Run model training test\n",
    "models_ok, model_results = test_model_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 5. Prediction System Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction_system():\n",
    "    \"\"\"Test the prediction system\"\"\"\n",
    "    print(\"\\n=== TESTING PREDICTION SYSTEM ===\")\n",
    "\n",
    "    if not models_ok:\n",
    "        print(\"âŒ Cannot test predictions - model training failed\")\n",
    "        return False, None\n",
    "\n",
    "    try:\n",
    "        from predictor import RiskPredictor\n",
    "\n",
    "        predictor = RiskPredictor()\n",
    "        print(\"âœ… Predictor initialized and models loaded\")\n",
    "\n",
    "        # Prepare data for prediction (use latest features for each trader)\n",
    "        prediction_data = {}\n",
    "        for account_id in all_data.keys():\n",
    "            if account_id in features_df[\"account_id\"].values:\n",
    "                trader_features = features_df[features_df[\"account_id\"] == account_id]\n",
    "                prediction_data[account_id] = {\n",
    "                    \"features\": trader_features,\n",
    "                    \"name\": all_data[account_id][\"name\"],\n",
    "                }\n",
    "\n",
    "        # Generate predictions\n",
    "        predictions = predictor.predict_all_traders(prediction_data)\n",
    "\n",
    "        print(f\"âœ… Predictions generated for {len(predictions)} traders\")\n",
    "\n",
    "        # Display prediction summary\n",
    "        risk_counts = {\"High\": 0, \"Medium\": 0, \"Low\": 0, \"Unknown\": 0}\n",
    "        for pred in predictions:\n",
    "            risk_level = pred.get(\"risk_level\", \"Unknown\")\n",
    "            risk_counts[risk_level] += 1\n",
    "\n",
    "        print(f\"ðŸ“Š Risk Distribution:\")\n",
    "        for level, count in risk_counts.items():\n",
    "            print(f\"   {level}: {count} traders\")\n",
    "\n",
    "        # Show sample predictions\n",
    "        print(f\"\\nðŸ“‹ Sample Predictions:\")\n",
    "        for pred in predictions[:3]:\n",
    "            print(\n",
    "                f\"   {pred['trader_name']}: {pred['risk_level']} risk, Predicted P&L: ${pred['predicted_pnl']:.2f}\"\n",
    "            )\n",
    "\n",
    "        return True, predictions\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Prediction system failed: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "        return False, None\n",
    "\n",
    "\n",
    "# Run prediction system test\n",
    "predictions_ok, predictions = test_prediction_system()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## 6. Email Service Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_email_service():\n",
    "    \"\"\"Test email service (without actually sending)\"\"\"\n",
    "    print(\"\\n=== TESTING EMAIL SERVICE ===\")\n",
    "\n",
    "    if not predictions_ok or not predictions:\n",
    "        print(\"âŒ Cannot test email - predictions failed\")\n",
    "        return False\n",
    "\n",
    "    try:\n",
    "        from email_service import EmailService\n",
    "\n",
    "        email_service = EmailService(config)\n",
    "\n",
    "        # Test email content creation\n",
    "        html_content = email_service.create_email_content(predictions)\n",
    "\n",
    "        print(\"âœ… Email content generated successfully\")\n",
    "        print(f\"   Content length: {len(html_content)} characters\")\n",
    "\n",
    "        # Save sample email for review\n",
    "        with open(\"sample_email.html\", \"w\") as f:\n",
    "            f.write(html_content)\n",
    "        print(\"âœ… Sample email saved as 'sample_email.html'\")\n",
    "\n",
    "        # Note: Don't actually send email in testing\n",
    "        print(\"ðŸ“§ Email service ready (test send disabled)\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Email service failed: {e}\")\n",
    "        import traceback\n",
    "\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "\n",
    "# Run email service test\n",
    "email_ok = test_email_service()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 7. End-to-End Integration Test\n",
    "\n",
    "\n",
    "def test_integration():\n",
    "    \"\"\"Test the complete pipeline\"\"\"\n",
    "    print(\"\\n=== INTEGRATION TEST SUMMARY ===\")\n",
    "\n",
    "    components = {\n",
    "        \"Environment\": env_ok,\n",
    "        \"Data Loading\": data_ok,\n",
    "        \"Feature Engineering\": features_ok,\n",
    "        \"Model Training\": models_ok,\n",
    "        \"Prediction System\": predictions_ok,\n",
    "        \"Email Service\": email_ok,\n",
    "    }\n",
    "\n",
    "    all_ok = all(components.values())\n",
    "\n",
    "    print(\n",
    "        f\"ðŸŽ¯ OVERALL STATUS: {'âœ… READY FOR PRODUCTION' if all_ok else 'âŒ NEEDS FIXES'}\"\n",
    "    )\n",
    "    print(f\"\\nComponent Status:\")\n",
    "    for component, status in components.items():\n",
    "        print(f\"   {component}: {'âœ…' if status else 'âŒ'}\")\n",
    "\n",
    "    if all_ok:\n",
    "        print(f\"\\nðŸš€ READY TO DEPLOY!\")\n",
    "        print(f\"   - {len(all_data)} traders monitored\")\n",
    "        print(f\"   - {len(feature_columns)} features engineered\")\n",
    "        print(\n",
    "            f\"   - Global + {len(personal_models) if models_ok else 0} personal models trained\"\n",
    "        )\n",
    "        print(f\"   - Email reporting configured\")\n",
    "\n",
    "        # Save integration test results\n",
    "        test_results = {\n",
    "            \"timestamp\": pd.Timestamp.now().isoformat(),\n",
    "            \"component_status\": components,\n",
    "            \"trader_count\": len(all_data) if all_data else 0,\n",
    "            \"feature_count\": len(feature_columns) if feature_columns else 0,\n",
    "            \"model_performance\": model_results if models_ok else None,\n",
    "        }\n",
    "\n",
    "        import json\n",
    "\n",
    "        with open(\"integration_test_results.json\", \"w\") as f:\n",
    "            json.dump(test_results, f, indent=2, default=str)\n",
    "        print(\"âœ… Test results saved to 'integration_test_results.json'\")\n",
    "\n",
    "    else:\n",
    "        print(f\"\\nðŸ”§ FIXES NEEDED:\")\n",
    "        for component, status in components.items():\n",
    "            if not status:\n",
    "                print(f\"   - Fix {component}\")\n",
    "\n",
    "    return all_ok\n",
    "\n",
    "\n",
    "# Run integration test\n",
    "integration_ok = test_integration()\n",
    "\n",
    "# %% [markdown]\n",
    "# ## 8. Manual Testing & Debugging Functions\n",
    "\n",
    "\n",
    "def debug_trader_data(account_id):\n",
    "    \"\"\"Debug specific trader data\"\"\"\n",
    "    if not all_data or account_id not in all_data:\n",
    "        print(f\"Trader {account_id} not found\")\n",
    "        return\n",
    "\n",
    "    trader = all_data[account_id]\n",
    "    print(f\"\\n=== DEBUG: {trader['name']} ({account_id}) ===\")\n",
    "\n",
    "    totals = trader[\"totals\"]\n",
    "    fills = trader[\"fills\"]\n",
    "\n",
    "    print(f\"Totals Data:\")\n",
    "    print(f\"  Shape: {totals.shape}\")\n",
    "    print(f\"  Date range: {totals['date'].min()} to {totals['date'].max()}\")\n",
    "    print(f\"  Total P&L: ${totals['net_pnl'].sum():,.2f}\")\n",
    "    print(f\"  Average daily P&L: ${totals['net_pnl'].mean():.2f}\")\n",
    "    print(f\"  Win rate: {(totals['net_pnl'] > 0).mean():.1%}\")\n",
    "\n",
    "    print(f\"\\nFills Data:\")\n",
    "    print(f\"  Shape: {fills.shape}\")\n",
    "    print(f\"  Unique symbols: {fills['symbol'].nunique()}\")\n",
    "    print(f\"  Average trade size: ${(fills['qty'] * fills['price']).mean():,.2f}\")\n",
    "\n",
    "    return totals, fills\n",
    "\n",
    "\n",
    "def debug_features(account_id):\n",
    "    \"\"\"Debug features for specific trader\"\"\"\n",
    "    if not features_ok:\n",
    "        print(\"Features not available\")\n",
    "        return\n",
    "\n",
    "    trader_features = features_df[features_df[\"account_id\"] == account_id]\n",
    "    if trader_features.empty:\n",
    "        print(f\"No features found for trader {account_id}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n=== FEATURES DEBUG: {account_id} ===\")\n",
    "    print(f\"Feature samples: {len(trader_features)}\")\n",
    "    print(f\"Target distribution: {trader_features['target'].value_counts().to_dict()}\")\n",
    "\n",
    "    # Show latest features\n",
    "    latest = trader_features.iloc[-1]\n",
    "    print(f\"\\nLatest Features:\")\n",
    "    for col in feature_columns:\n",
    "        print(f\"  {col}: {latest[col]:.4f}\")\n",
    "\n",
    "    return trader_features\n",
    "\n",
    "\n",
    "def debug_prediction(account_id):\n",
    "    \"\"\"Debug prediction for specific trader\"\"\"\n",
    "    if not predictions_ok:\n",
    "        print(\"Predictions not available\")\n",
    "        return\n",
    "\n",
    "    pred = next((p for p in predictions if p[\"account_id\"] == account_id), None)\n",
    "    if not pred:\n",
    "        print(f\"No prediction found for trader {account_id}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n=== PREDICTION DEBUG: {account_id} ===\")\n",
    "    for key, value in pred.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"  {key}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"  {key}: {value}\")\n",
    "\n",
    "    return pred\n",
    "\n",
    "\n",
    "# Example usage functions\n",
    "print(f\"\\n=== MANUAL DEBUGGING FUNCTIONS AVAILABLE ===\")\n",
    "print(f\"- debug_trader_data('account_id')\")\n",
    "print(f\"- debug_features('account_id')\")\n",
    "print(f\"- debug_prediction('account_id')\")\n",
    "\n",
    "if all_data:\n",
    "    first_trader = list(all_data.keys())[0]\n",
    "    print(f\"\\nExample: debug_trader_data('{first_trader}')\")\n",
    "\n",
    "print(f\"\\n=== NOTEBOOK READY FOR DEBUGGING ===\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "risk-tool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
