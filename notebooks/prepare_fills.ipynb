{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "accounts_list = [\n",
    "    \"NETS012_OLD\",\n",
    "    \"NECS008OP_OLD\",\n",
    "    \"NEL004_OLD\",\n",
    "    \"NEO006MS_OLD\",\n",
    "    \"NEO004OP_OLD\",\n",
    "]\n",
    "\n",
    "accounts_id_map = {\n",
    "    \"NETS012_OLD\": 4766,\n",
    "    \"NECS008OP_OLD\": 6973,\n",
    "    \"NEL004_OLD\": 4003,\n",
    "    \"NEO006MS_OLD\": 5190,\n",
    "    \"NEO004OP_OLD\": 3976,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "account = \"NETS012_OLD\"\n",
    "account_id = accounts_id_map.get(account)\n",
    "assert account_id is not None, f\"Account ID for {account} not found.\"\n",
    "print(f\"Account ID for {account} is {account_id}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACCOUNT_ID = \"6973\"\n",
    "ACCOUNT_NAME = \"NECS008OP_OLD\"\n",
    "PATH_DIR = f\"../data/raw/fills/{ACCOUNT_ID}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "from io import StringIO\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# read all csv files in the directory and combine them into a single dataframe\n",
    "def read_csv_files_in_directory(directory):\n",
    "    path_pattern = os.path.join(directory, \"*.csv\")\n",
    "\n",
    "    # Get a list of all matching files\n",
    "    csv_files = glob.glob(path_pattern)\n",
    "    print(f\"Found {len(csv_files)} files.\")\n",
    "    df_list = []\n",
    "\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(file)\n",
    "        df_list.append(df)\n",
    "\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "fills = read_csv_files_in_directory(PATH_DIR)\n",
    "\n",
    "\n",
    "fills.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fills.drop(\n",
    "    columns=[\n",
    "        \"Route\",\n",
    "        \"Liq\",\n",
    "        \"Fill Id\",\n",
    "        \"Currency\",\n",
    "        \"ISIN\",\n",
    "        \"CUSIP\",\n",
    "        \"Status\",\n",
    "        \"PropReports Id\",\n",
    "    ],\n",
    "    inplace=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fills[\"Date/Time\"] = pd.to_datetime(fills[\"Date/Time\"])\n",
    "fills.sort_values(by=\"Date/Time\")\n",
    "fee_columns = [\n",
    "    \"Comm\",\n",
    "    \"Ecn Fee\",\n",
    "    \"SEC\",\n",
    "    \"ORF\",\n",
    "    \"CAT\",\n",
    "    \"TAF\",\n",
    "    \"FTT\",\n",
    "    \"NSCC\",\n",
    "    \"Acc\",\n",
    "    \"Clr\",\n",
    "    \"Misc\",\n",
    "]\n",
    "fills[\"fee\"] = fills[fee_columns].sum(axis=1)\n",
    "fills.drop(fee_columns, axis=1, inplace=True)\n",
    "display(fills.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fills = fills.rename(\n",
    "    mapper={\n",
    "        \"Date/Time\": \"date_time\",\n",
    "        \"Account\": \"account\",\n",
    "        \"B/S\": \"trade_side\",\n",
    "        \"Qty\": \"quantity\",\n",
    "        \"Symbol\": \"symbol\",\n",
    "        \"Price\": \"price\",\n",
    "        \"Order Id\": \"order_id\",\n",
    "    },\n",
    "    axis=1,\n",
    ")\n",
    "fills.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fills[\"date\"] = fills[\"date_time\"].dt.date\n",
    "\n",
    "\n",
    "agg_map_day = {\n",
    "    \"quantity\": \"sum\",\n",
    "    # price → average_price\n",
    "    \"price\": lambda x: np.average(x, weights=fills.loc[x.index, \"quantity\"]),\n",
    "    \"fee\": \"sum\",\n",
    "}\n",
    "\n",
    "df_daily = (\n",
    "    fills.groupby([\"date\", \"symbol\", \"trade_side\"])\n",
    "    .agg(agg_map_day)\n",
    "    .rename(\n",
    "        columns={\"price\": \"average_price\"}\n",
    "    )  # rename the “price” column to average_price\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fills[\"value\"] = np.where(\n",
    "    fills[\"trade_side\"] == \"B\",\n",
    "    -fills[\"quantity\"] * fills[\"price\"],\n",
    "    fills[\"quantity\"] * fills[\"price\"],\n",
    ")\n",
    "group = (\n",
    "    fills.groupby([\"date\", \"symbol\"])\n",
    "    .agg(\n",
    "        fills=(\"quantity\", \"count\"),  # how many fills\n",
    "        qty=(\"quantity\", \"sum\"),  # total quantity traded\n",
    "        gross=(\"value\", \"sum\"),  # P/L before fees\n",
    "        comm=(\"fee\", \"sum\"),  # total commission/fees\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "group[\"net\"] = group[\"gross\"] - group[\"comm\"]\n",
    "\n",
    "display(group.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
