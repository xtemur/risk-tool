{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Validation: Fills vs Summary\n",
    "Validate consistency between fills table and account_daily_summary table"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Add the parent directory to the path so we can import from src\n",
    "parent_dir = Path(__file__).parent.parent if '__file__' in globals() else Path.cwd().parent\n",
    "sys.path.insert(0, str(parent_dir))\n",
    "\n",
    "# Change working directory to the project root if we're in notebooks folder\n",
    "if Path.cwd().name == 'notebooks':\n",
    "    os.chdir(parent_dir)\n",
    "    print(f\"Changed working directory to: {Path.cwd()}\")\n",
    "\n",
    "# Import our data validation functions\n",
    "from src.data.database_manager import DatabaseManager\n",
    "from src.data.data_validator import validate_data_fast, validate_data_full\n",
    "\n",
    "# Initialize database manager - it will now look for the database in the correct location\n",
    "db = DatabaseManager()\n",
    "\n",
    "print(\"üîç Data Validation Notebook\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Working directory: {Path.cwd()}\")\n",
    "print(f\"Database path: {db.db_path}\")\n",
    "\n",
    "# Get basic database stats\n",
    "try:\n",
    "    stats = db.get_database_stats()\n",
    "    print(\"\\nDatabase Statistics:\")\n",
    "    for key, value in stats.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Error reading database: {e}\")\n",
    "    print(\"Make sure you've run 'python scripts/setup_database.py' first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data using our database manager\n",
    "accounts = db.get_accounts()\n",
    "summary_data = db.get_summary_data()\n",
    "fills_data = db.get_fills_data()\n",
    "\n",
    "print(\"üìä Data Overview:\")\n",
    "print(f\"Accounts: {len(accounts)}\")\n",
    "print(f\"Summary records: {len(summary_data)}\")\n",
    "print(f\"Fills records: {len(fills_data)}\")\n",
    "\n",
    "print(\"\\nüìÖ Date Ranges:\")\n",
    "if not summary_data.empty:\n",
    "    print(f\"Summary: {summary_data['date'].min()} to {summary_data['date'].max()}\")\n",
    "if not fills_data.empty:\n",
    "    print(f\"Fills: {fills_data['datetime'].min()} to {fills_data['datetime'].max()}\")\n",
    "\n",
    "print(\"\\nüë• Accounts:\")\n",
    "print(accounts[['account_id', 'account_name', 'account_type']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ Run Fast Validation (Aggregate Comparison)\n",
    "print(\"üöÄ Running Fast Validation...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "fast_validation = validate_data_fast()\n",
    "fast_stats = fast_validation['stats']\n",
    "\n",
    "print(f\"‚úÖ Total accounts: {fast_stats['total_accounts']}\")\n",
    "print(f\"‚úÖ Accounts with data: {fast_stats['accounts_with_data']}\")\n",
    "print(f\"‚úÖ Failed validation: {fast_stats['failed_validation']}\")\n",
    "\n",
    "if 'portfolio' in fast_stats:\n",
    "    ps = fast_stats['portfolio']\n",
    "    print(f\"\\nüí∞ Portfolio Overview:\")\n",
    "    print(f\"  Total P&L: ${ps['total_pnl']:,.2f}\")\n",
    "    print(f\"  Total Volume: {ps['total_volume']:,.0f} shares\")\n",
    "    print(f\"  Total Trades: {ps['total_trades']:,}\")\n",
    "    win_rate = ps['total_profitable_days'] / (ps['total_profitable_days'] + ps['total_losing_days']) * 100\n",
    "    print(f\"  Win Rate: {win_rate:.1f}%\")\n",
    "\n",
    "# Show any warnings\n",
    "if fast_validation['warnings']:\n",
    "    print(f\"\\n‚ö†Ô∏è  Validation Warnings:\")\n",
    "    for warning in fast_validation['warnings']:\n",
    "        print(f\"  {warning}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìà Account Performance Analysis\n",
    "print(\"üìà Account Performance Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "account_performance = []\n",
    "\n",
    "for acc_id, acc_stats in fast_stats['by_account'].items():\n",
    "    if acc_stats.get('trading_stats'):\n",
    "        ts = acc_stats['trading_stats']\n",
    "        performance = {\n",
    "            'Account ID': acc_id,\n",
    "            'Total P&L': ts['total_pnl'],\n",
    "            'Win Rate (%)': ts['profitable_days'] / (ts['profitable_days'] + ts['losing_days']) * 100,\n",
    "            'Avg Daily P&L': ts['avg_daily_pnl'],\n",
    "            'Max Daily Gain': ts['max_daily_pnl'],\n",
    "            'Max Daily Loss': ts['min_daily_pnl'],\n",
    "            'Total Trades': ts['total_trades'],\n",
    "            'Total Volume': ts['total_volume'],\n",
    "            'Trading Days': ts['trading_days']\n",
    "        }\n",
    "        account_performance.append(performance)\n",
    "\n",
    "# Create DataFrame for easier analysis\n",
    "perf_df = pd.DataFrame(account_performance)\n",
    "\n",
    "# Display top performers\n",
    "print(\"üèÜ Top Performers by Total P&L:\")\n",
    "top_performers = perf_df.nlargest(5, 'Total P&L')[['Account ID', 'Total P&L', 'Win Rate (%)', 'Trading Days']]\n",
    "print(top_performers.to_string(index=False))\n",
    "\n",
    "print(\"\\nüìä Performance Summary:\")\n",
    "print(f\"Best performing account: {perf_df.loc[perf_df['Total P&L'].idxmax(), 'Account ID']} (${perf_df['Total P&L'].max():,.2f})\")\n",
    "print(f\"Worst performing account: {perf_df.loc[perf_df['Total P&L'].idxmin(), 'Account ID']} (${perf_df['Total P&L'].min():,.2f})\")\n",
    "print(f\"Average win rate: {perf_df['Win Rate (%)'].mean():.1f}%\")\n",
    "print(f\"Best single day: ${perf_df['Max Daily Gain'].max():,.2f}\")\n",
    "print(f\"Worst single day: ${perf_df['Max Daily Loss'].min():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Performance Visualization\n",
    "print(\"üìä Creating Performance Visualizations...\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Trading Performance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Total P&L by Account\n",
    "ax1 = axes[0, 0]\n",
    "colors = ['green' if x > 0 else 'red' for x in perf_df['Total P&L']]\n",
    "bars = ax1.bar(range(len(perf_df)), perf_df['Total P&L'], color=colors, alpha=0.7)\n",
    "ax1.set_xlabel('Account Index')\n",
    "ax1.set_ylabel('Total P&L ($)')\n",
    "ax1.set_title('Total P&L by Account')\n",
    "ax1.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, (bar, value) in enumerate(zip(bars, perf_df['Total P&L'])):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + (max(perf_df['Total P&L']) * 0.01),\n",
    "             f'${value:,.0f}', ha='center', va='bottom', fontsize=8, rotation=45)\n",
    "\n",
    "# 2. Win Rate Distribution\n",
    "ax2 = axes[0, 1]\n",
    "ax2.hist(perf_df['Win Rate (%)'], bins=10, alpha=0.7, color='blue', edgecolor='black')\n",
    "ax2.axvline(x=50, color='red', linestyle='--', label='Break-even (50%)')\n",
    "ax2.set_xlabel('Win Rate (%)')\n",
    "ax2.set_ylabel('Number of Accounts')\n",
    "ax2.set_title('Win Rate Distribution')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Trading Volume vs P&L\n",
    "ax3 = axes[1, 0]\n",
    "scatter = ax3.scatter(perf_df['Total Volume'], perf_df['Total P&L'], \n",
    "                     c=perf_df['Win Rate (%)'], cmap='RdYlGn', \n",
    "                     s=perf_df['Trading Days']*2, alpha=0.7)\n",
    "ax3.set_xlabel('Total Volume (Shares)')\n",
    "ax3.set_ylabel('Total P&L ($)')\n",
    "ax3.set_title('Volume vs P&L (Size = Trading Days)')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "plt.colorbar(scatter, ax=ax3, label='Win Rate (%)')\n",
    "\n",
    "# 4. Risk-Return Profile (Max Loss vs Max Gain)\n",
    "ax4 = axes[1, 1]\n",
    "ax4.scatter(abs(perf_df['Max Daily Loss']), perf_df['Max Daily Gain'], \n",
    "           c=perf_df['Total P&L'], cmap='RdYlGn', s=100, alpha=0.7)\n",
    "ax4.set_xlabel('Max Daily Loss ($)')\n",
    "ax4.set_ylabel('Max Daily Gain ($)')\n",
    "ax4.set_title('Risk-Return Profile')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Add diagonal line (equal risk-reward)\n",
    "max_val = max(ax4.get_xlim()[1], ax4.get_ylim()[1])\n",
    "ax4.plot([0, max_val], [0, max_val], 'r--', alpha=0.5, label='Equal Risk-Reward')\n",
    "ax4.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¨ Deep Dive: Data Quality Analysis\n",
    "print(\"üî¨ Deep Dive: Data Quality Analysis\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check data quality for each account\n",
    "print(\"üîç Data Quality by Account:\")\n",
    "for acc_id, acc_stats in fast_stats['by_account'].items():\n",
    "    print(f\"\\nüìã Account {acc_id}:\")\n",
    "    print(f\"  Summary records: {acc_stats['summary_records']}\")\n",
    "    print(f\"  Fills records: {acc_stats['fills_records']}\")\n",
    "    \n",
    "    if acc_stats.get('date_range'):\n",
    "        dr = acc_stats['date_range']\n",
    "        print(f\"  Date range: {dr['start']} to {dr['end']} ({dr['days']} days)\")\n",
    "    \n",
    "    # Check for fast validation results\n",
    "    if acc_stats.get('fast_validation'):\n",
    "        fv = acc_stats['fast_validation']\n",
    "        if fv.get('discrepancies'):\n",
    "            print(f\"  üîç Aggregate Validation:\")\n",
    "            for metric, disc in fv['discrepancies'].items():\n",
    "                diff_pct = disc['diff_pct']\n",
    "                if diff_pct != float('inf') and diff_pct > 0.02:  # > 2% difference\n",
    "                    print(f\"    ‚ö†Ô∏è  {metric}: {diff_pct:.1%} difference\")\n",
    "                else:\n",
    "                    print(f\"    ‚úÖ {metric}: Good match\")\n",
    "\n",
    "# Data coverage analysis\n",
    "print(f\"\\nüìÖ Data Coverage Analysis:\")\n",
    "total_expected_days = (summary_data['date'].max() - summary_data['date'].min()).days + 1\n",
    "weekdays_expected = pd.bdate_range(summary_data['date'].min(), summary_data['date'].max())\n",
    "print(f\"Total period: {total_expected_days} days\")\n",
    "print(f\"Trading days expected: {len(weekdays_expected)} days\")\n",
    "print(f\"Actual summary records: {len(summary_data)} days\")\n",
    "coverage_pct = len(summary_data) / len(weekdays_expected) * 100\n",
    "print(f\"Coverage rate: {coverage_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üêå Full Validation (Day-by-Day Analysis)\n",
    "print(\"üêå Running Full Validation (Day-by-Day)...\")\n",
    "print(\"=\" * 50)\n",
    "print(\"‚è≥ This may take a moment...\")\n",
    "\n",
    "# Run full validation for detailed day-by-day analysis\n",
    "full_validation = validate_data_full()\n",
    "full_stats = full_validation['stats']\n",
    "\n",
    "print(f\"‚úÖ Full validation complete!\")\n",
    "print(f\"üìä Results:\")\n",
    "print(f\"  Failed validation: {full_stats['failed_validation']}\")\n",
    "print(f\"  Total discrepancy days: {full_stats['total_discrepancy_days']}\")\n",
    "\n",
    "# Show accounts with slow validation results\n",
    "accounts_with_daily_issues = 0\n",
    "for acc_id, acc_stats in full_stats['by_account'].items():\n",
    "    if acc_stats.get('slow_validation'):\n",
    "        sv = acc_stats['slow_validation']\n",
    "        if sv.get('daily_discrepancies'):\n",
    "            accounts_with_daily_issues += 1\n",
    "            print(f\"\\nüìã Account {acc_id} - Daily Validation:\")\n",
    "            print(f\"  Total compared days: {sv['stats']['total_compared_days']}\")\n",
    "            print(f\"  Discrepancy days: {sv['stats']['discrepancy_days']}\")\n",
    "            print(f\"  Discrepancy rate: {sv['stats']['discrepancy_rate']:.1%}\")\n",
    "            \n",
    "            # Show first few discrepancies as examples\n",
    "            if len(sv['daily_discrepancies']) > 0:\n",
    "                print(f\"  Sample discrepancies:\")\n",
    "                for i, disc in enumerate(sv['daily_discrepancies'][:3]):\n",
    "                    print(f\"    {disc['date']}: {', '.join(disc['issues'])}\")\n",
    "                if len(sv['daily_discrepancies']) > 3:\n",
    "                    print(f\"    ... and {len(sv['daily_discrepancies']) - 3} more\")\n",
    "\n",
    "print(f\"\\nüìà Summary:\")\n",
    "print(f\"Accounts with daily-level discrepancies: {accounts_with_daily_issues}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Time Series Analysis: Daily P&L Trends\n",
    "print(\"üìä Time Series Analysis: Daily P&L Trends\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Analyze daily P&L patterns\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Daily P&L Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Get daily P&L for all accounts\n",
    "daily_pnl_data = []\n",
    "for acc_id in accounts['account_id']:\n",
    "    acc_summary = db.get_summary_data(account_id=acc_id)\n",
    "    if not acc_summary.empty:\n",
    "        acc_summary['account_id'] = acc_id\n",
    "        daily_pnl_data.append(acc_summary[['account_id', 'date', 'net']])\n",
    "\n",
    "if daily_pnl_data:\n",
    "    all_daily_pnl = pd.concat(daily_pnl_data, ignore_index=True)\n",
    "    \n",
    "    # 1. Daily P&L Distribution\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.hist(all_daily_pnl['net'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    ax1.axvline(x=0, color='red', linestyle='--', label='Break-even')\n",
    "    ax1.set_xlabel('Daily P&L ($)')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.set_title('Daily P&L Distribution (All Accounts)')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Cumulative P&L Over Time\n",
    "    ax2 = axes[0, 1]\n",
    "    portfolio_daily = all_daily_pnl.groupby('date')['net'].sum().reset_index()\n",
    "    portfolio_daily['cumulative_pnl'] = portfolio_daily['net'].cumsum()\n",
    "    ax2.plot(portfolio_daily['date'], portfolio_daily['cumulative_pnl'], linewidth=2, color='green')\n",
    "    ax2.set_xlabel('Date')\n",
    "    ax2.set_ylabel('Cumulative P&L ($)')\n",
    "    ax2.set_title('Portfolio Cumulative P&L')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # 3. Monthly P&L Heatmap\n",
    "    ax3 = axes[1, 0]\n",
    "    all_daily_pnl['year_month'] = all_daily_pnl['date'].dt.to_period('M')\n",
    "    monthly_pnl = all_daily_pnl.groupby(['account_id', 'year_month'])['net'].sum().reset_index()\n",
    "    \n",
    "    # Create pivot table for heatmap\n",
    "    if len(monthly_pnl) > 0:\n",
    "        heatmap_data = monthly_pnl.pivot(index='account_id', columns='year_month', values='net')\n",
    "        sns.heatmap(heatmap_data, annot=False, cmap='RdYlGn', center=0, ax=ax3)\n",
    "        ax3.set_title('Monthly P&L by Account')\n",
    "        ax3.set_xlabel('Month')\n",
    "        ax3.set_ylabel('Account ID')\n",
    "    \n",
    "    # 4. Volatility Analysis (Rolling Std)\n",
    "    ax4 = axes[1, 1]\n",
    "    portfolio_daily['rolling_std'] = portfolio_daily['net'].rolling(window=20).std()\n",
    "    ax4.plot(portfolio_daily['date'], portfolio_daily['rolling_std'], color='orange', linewidth=2)\n",
    "    ax4.set_xlabel('Date')\n",
    "    ax4.set_ylabel('20-Day Rolling Std ($)')\n",
    "    ax4.set_title('Portfolio Volatility (Rolling Std)')\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìã Final Validation Report\n",
    "print(\"üìã Final Validation Report\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Combine all validation results\n",
    "validation_summary = {\n",
    "    'timestamp': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'total_accounts': fast_stats['total_accounts'],\n",
    "    'accounts_with_data': fast_stats['accounts_with_data'],\n",
    "    'total_summary_records': len(summary_data),\n",
    "    'total_fills_records': len(fills_data),\n",
    "    'data_date_range': {\n",
    "        'start': summary_data['date'].min().strftime('%Y-%m-%d') if not summary_data.empty else 'N/A',\n",
    "        'end': summary_data['date'].max().strftime('%Y-%m-%d') if not summary_data.empty else 'N/A'\n",
    "    },\n",
    "    'portfolio_performance': fast_stats.get('portfolio', {}),\n",
    "    'validation_status': {\n",
    "        'fast_validation_passed': fast_stats['failed_validation'] == 0,\n",
    "        'full_validation_passed': full_stats['failed_validation'] == 0,\n",
    "        'total_warnings': len(fast_validation['warnings']) + len(full_validation['warnings'])\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üéØ VALIDATION SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"‚úÖ Validation completed at: {validation_summary['timestamp']}\")\n",
    "print(f\"üìä Data Coverage:\")\n",
    "print(f\"  - Accounts: {validation_summary['total_accounts']}\")\n",
    "print(f\"  - Summary records: {validation_summary['total_summary_records']:,}\")\n",
    "print(f\"  - Fills records: {validation_summary['total_fills_records']:,}\")\n",
    "print(f\"  - Date range: {validation_summary['data_date_range']['start']} to {validation_summary['data_date_range']['end']}\")\n",
    "\n",
    "print(f\"\\nüí∞ Portfolio Performance:\")\n",
    "if validation_summary['portfolio_performance']:\n",
    "    pp = validation_summary['portfolio_performance']\n",
    "    print(f\"  - Total P&L: ${pp['total_pnl']:,.2f}\")\n",
    "    print(f\"  - Total Volume: {pp['total_volume']:,.0f} shares\")\n",
    "    print(f\"  - Total Trades: {pp['total_trades']:,}\")\n",
    "    win_rate = pp['total_profitable_days'] / (pp['total_profitable_days'] + pp['total_losing_days']) * 100\n",
    "    print(f\"  - Win Rate: {win_rate:.1f}%\")\n",
    "\n",
    "print(f\"\\nüîç Validation Status:\")\n",
    "vs = validation_summary['validation_status']\n",
    "print(f\"  - Fast validation: {'‚úÖ PASSED' if vs['fast_validation_passed'] else '‚ùå FAILED'}\")\n",
    "print(f\"  - Full validation: {'‚úÖ PASSED' if vs['full_validation_passed'] else '‚ùå FAILED'}\")\n",
    "print(f\"  - Total warnings: {vs['total_warnings']}\")\n",
    "\n",
    "print(f\"\\nüèÜ Top Performing Accounts:\")\n",
    "if not perf_df.empty:\n",
    "    top_3 = perf_df.nlargest(3, 'Total P&L')\n",
    "    for i, (_, account) in enumerate(top_3.iterrows(), 1):\n",
    "        print(f\"  {i}. Account {account['Account ID']}: ${account['Total P&L']:,.2f} ({account['Win Rate (%)']:.1f}% win rate)\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è  Accounts Needing Attention:\")\n",
    "if not perf_df.empty:\n",
    "    problem_accounts = perf_df[perf_df['Total P&L'] < 0]\n",
    "    if len(problem_accounts) > 0:\n",
    "        for _, account in problem_accounts.iterrows():\n",
    "            print(f\"  - Account {account['Account ID']}: ${account['Total P&L']:,.2f} loss\")\n",
    "    else:\n",
    "        print(\"  - No accounts with losses! üéâ\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"‚úÖ Data validation complete! All systems operational.\")\n",
    "print(\"üìà Ready for risk analysis and model development.\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìä Visual Analysis: Trading Activity Patterns\n",
    "print(\"üìä Visual Analysis: Trading Activity Patterns\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create visualizations for accounts with missing fills data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Trading Activity Analysis for Accounts 3957 and 3978', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, acc_id in enumerate(['3957', '3978']):\n",
    "    # Get account data\n",
    "    acc_summary = db.get_summary_data(account_id=acc_id)\n",
    "    \n",
    "    if not acc_summary.empty:\n",
    "        # Calculate monthly activity\n",
    "        acc_summary['year_month'] = acc_summary['date'].dt.to_period('M')\n",
    "        monthly_activity = acc_summary.groupby('year_month').agg({\n",
    "            'fills': 'sum',\n",
    "            'net': 'sum',\n",
    "            'date': 'count'\n",
    "        }).reset_index()\n",
    "        monthly_activity.columns = ['year_month', 'fills', 'net_pnl', 'days']\n",
    "        monthly_activity['active_days'] = acc_summary[acc_summary['fills'] > 0].groupby(\n",
    "            acc_summary['year_month']).size().reindex(monthly_activity['year_month']).fillna(0)\n",
    "        \n",
    "        # Plot 1 & 2: Monthly fills activity\n",
    "        ax = axes[0, i]\n",
    "        x = range(len(monthly_activity))\n",
    "        ax.bar(x, monthly_activity['fills'], alpha=0.7, color='blue', label='Total Fills')\n",
    "        ax.set_xlabel('Month')\n",
    "        ax.set_ylabel('Number of Fills')\n",
    "        ax.set_title(f'Account {acc_id}: Monthly Trading Activity')\n",
    "        ax.set_xticks(x[::3])  # Show every 3rd month\n",
    "        ax.set_xticklabels(monthly_activity['year_month'].astype(str).iloc[::3], rotation=45)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add activity rate on secondary axis\n",
    "        ax2 = ax.twinx()\n",
    "        activity_rate = (monthly_activity['active_days'] / monthly_activity['days'] * 100)\n",
    "        ax2.plot(x, activity_rate, color='red', marker='o', linestyle='-', linewidth=2, label='Activity Rate %')\n",
    "        ax2.set_ylabel('Activity Rate (%)', color='red')\n",
    "        ax2.tick_params(axis='y', labelcolor='red')\n",
    "        \n",
    "        # Plot 3 & 4: Trading intensity heatmap\n",
    "        ax = axes[1, i]\n",
    "        \n",
    "        # Create a calendar-like view of trading activity\n",
    "        acc_summary['day_of_week'] = acc_summary['date'].dt.dayofweek\n",
    "        acc_summary['week_of_year'] = acc_summary['date'].dt.isocalendar().week\n",
    "        acc_summary['year'] = acc_summary['date'].dt.year\n",
    "        \n",
    "        # Focus on most recent year\n",
    "        recent_year = acc_summary['year'].max()\n",
    "        recent_data = acc_summary[acc_summary['year'] == recent_year].copy()\n",
    "        \n",
    "        # Create pivot table for heatmap\n",
    "        if len(recent_data) > 0:\n",
    "            heatmap_data = recent_data.pivot_table(\n",
    "                values='fills', \n",
    "                index='day_of_week', \n",
    "                columns='week_of_year', \n",
    "                aggfunc='sum',\n",
    "                fill_value=0\n",
    "            )\n",
    "            \n",
    "            # Plot heatmap\n",
    "            sns.heatmap(heatmap_data, cmap='YlOrRd', ax=ax, cbar_kws={'label': 'Fills'})\n",
    "            ax.set_title(f'Account {acc_id}: {recent_year} Trading Intensity')\n",
    "            ax.set_xlabel('Week of Year')\n",
    "            ax.set_ylabel('Day of Week')\n",
    "            ax.set_yticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Additional analysis: Create a summary table\n",
    "print(\"\\nüìä Summary Table: Fills Data Completeness\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "summary_table = []\n",
    "for acc_id in accounts['account_id']:\n",
    "    acc_summary = db.get_summary_data(account_id=acc_id)\n",
    "    acc_fills = db.get_fills_data(account_id=acc_id)\n",
    "    \n",
    "    if not acc_summary.empty:\n",
    "        expected_fills = acc_summary['fills'].sum()\n",
    "        actual_fills = len(acc_fills)\n",
    "        capture_rate = actual_fills / expected_fills * 100 if expected_fills > 0 else 0\n",
    "        \n",
    "        # Get trading activity info\n",
    "        trading_days = (acc_summary['fills'] > 0).sum()\n",
    "        total_days = len(acc_summary)\n",
    "        activity_rate = trading_days / total_days * 100\n",
    "        \n",
    "        # Last trading info\n",
    "        last_trade_mask = acc_summary['fills'] > 0\n",
    "        if last_trade_mask.any():\n",
    "            last_trade_date = acc_summary.loc[last_trade_mask, 'date'].max()\n",
    "            days_inactive = (pd.Timestamp.now() - last_trade_date).days\n",
    "        else:\n",
    "            last_trade_date = 'Never'\n",
    "            days_inactive = 'N/A'\n",
    "        \n",
    "        summary_table.append({\n",
    "            'Account': acc_id,\n",
    "            'Expected Fills': expected_fills,\n",
    "            'Actual Fills': actual_fills,\n",
    "            'Capture Rate (%)': round(capture_rate, 1),\n",
    "            'Trading Days': trading_days,\n",
    "            'Total Days': total_days,\n",
    "            'Activity Rate (%)': round(activity_rate, 1),\n",
    "            'Last Trade': last_trade_date,\n",
    "            'Days Inactive': days_inactive\n",
    "        })\n",
    "\n",
    "# Convert to DataFrame and display\n",
    "summary_df = pd.DataFrame(summary_table)\n",
    "summary_df = summary_df.sort_values('Capture Rate (%)')\n",
    "\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Highlight accounts with issues\n",
    "print(\"\\n‚ö†Ô∏è  Accounts Requiring Attention:\")\n",
    "problem_accounts = summary_df[summary_df['Capture Rate (%)'] < 90]\n",
    "if len(problem_accounts) > 0:\n",
    "    for _, acc in problem_accounts.iterrows():\n",
    "        print(f\"  - Account {acc['Account']}: Only {acc['Capture Rate (%)']}% fills captured\")\n",
    "        if acc['Days Inactive'] != 'N/A' and isinstance(acc['Days Inactive'], (int, float)) and acc['Days Inactive'] > 30:\n",
    "            print(f\"    ‚Üí Inactive for {acc['Days Inactive']} days\")\n",
    "else:\n",
    "    print(\"  ‚úÖ All accounts have good fill data capture rates!\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç Special Analysis: Accounts with Missing Fills Data\n",
    "print(\"üîç Special Analysis: Accounts with Missing Fills Data\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Analyze accounts that have summary data but missing or incomplete fills data\n",
    "accounts_with_issues = []\n",
    "\n",
    "for acc_id in accounts['account_id']:\n",
    "    acc_summary = db.get_summary_data(account_id=acc_id)\n",
    "    acc_fills = db.get_fills_data(account_id=acc_id)\n",
    "    \n",
    "    if not acc_summary.empty:\n",
    "        # Calculate expected vs actual fills\n",
    "        summary_fills_count = acc_summary['fills'].sum()\n",
    "        actual_fills_count = len(acc_fills)\n",
    "        \n",
    "        # Check for significant discrepancies\n",
    "        if summary_fills_count > 0 and actual_fills_count == 0:\n",
    "            # Account has fills in summary but no fills data\n",
    "            accounts_with_issues.append({\n",
    "                'account_id': acc_id,\n",
    "                'issue': 'NO_FILLS_DATA',\n",
    "                'summary_fills': summary_fills_count,\n",
    "                'actual_fills': actual_fills_count,\n",
    "                'trading_days': (acc_summary['fills'] > 0).sum(),\n",
    "                'date_range': f\"{acc_summary['date'].min()} to {acc_summary['date'].max()}\"\n",
    "            })\n",
    "        elif abs(summary_fills_count - actual_fills_count) > summary_fills_count * 0.1:  # >10% difference\n",
    "            accounts_with_issues.append({\n",
    "                'account_id': acc_id,\n",
    "                'issue': 'FILLS_MISMATCH',\n",
    "                'summary_fills': summary_fills_count,\n",
    "                'actual_fills': actual_fills_count,\n",
    "                'trading_days': (acc_summary['fills'] > 0).sum(),\n",
    "                'date_range': f\"{acc_summary['date'].min()} to {acc_summary['date'].max()}\"\n",
    "            })\n",
    "\n",
    "# Display findings\n",
    "if accounts_with_issues:\n",
    "    print(f\"‚ö†Ô∏è  Found {len(accounts_with_issues)} accounts with fills data issues:\\n\")\n",
    "    \n",
    "    for issue in accounts_with_issues:\n",
    "        print(f\"üìã Account {issue['account_id']}:\")\n",
    "        print(f\"   Issue: {issue['issue']}\")\n",
    "        print(f\"   Summary shows: {issue['summary_fills']:,} fills\")\n",
    "        print(f\"   Database has: {issue['actual_fills']:,} fills\")\n",
    "        print(f\"   Trading days: {issue['trading_days']}\")\n",
    "        print(f\"   Date range: {issue['date_range']}\")\n",
    "        print()\n",
    "\n",
    "# Deep dive into accounts 3957 and 3978\n",
    "print(\"\\nüìä Deep Analysis: Accounts 3957 and 3978\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for acc_id in ['3957', '3978']:\n",
    "    print(f\"\\nüîé Account {acc_id}:\")\n",
    "    \n",
    "    # Get summary data\n",
    "    acc_summary = db.get_summary_data(account_id=acc_id)\n",
    "    acc_fills = db.get_fills_data(account_id=acc_id)\n",
    "    \n",
    "    if not acc_summary.empty:\n",
    "        # Analyze trading patterns\n",
    "        trading_days = acc_summary[acc_summary['fills'] > 0]\n",
    "        non_trading_days = acc_summary[acc_summary['fills'] == 0]\n",
    "        \n",
    "        print(f\"  Total days: {len(acc_summary)}\")\n",
    "        print(f\"  Trading days: {len(trading_days)} ({len(trading_days)/len(acc_summary)*100:.1f}%)\")\n",
    "        print(f\"  Non-trading days: {len(non_trading_days)} ({len(non_trading_days)/len(acc_summary)*100:.1f}%)\")\n",
    "        \n",
    "        # Find periods of inactivity\n",
    "        acc_summary['is_trading'] = acc_summary['fills'] > 0\n",
    "        acc_summary['inactive_streak'] = (~acc_summary['is_trading']).cumsum()\n",
    "        acc_summary['inactive_streak'][acc_summary['is_trading']] = 0\n",
    "        \n",
    "        # Find longest inactive periods\n",
    "        inactive_periods = []\n",
    "        current_period = {'start': None, 'end': None, 'days': 0}\n",
    "        \n",
    "        for idx, row in acc_summary.iterrows():\n",
    "            if row['fills'] == 0:\n",
    "                if current_period['start'] is None:\n",
    "                    current_period['start'] = row['date']\n",
    "                current_period['end'] = row['date']\n",
    "                current_period['days'] += 1\n",
    "            else:\n",
    "                if current_period['start'] is not None:\n",
    "                    inactive_periods.append(current_period.copy())\n",
    "                    current_period = {'start': None, 'end': None, 'days': 0}\n",
    "        \n",
    "        # Don't forget the last period if it ends with inactivity\n",
    "        if current_period['start'] is not None:\n",
    "            inactive_periods.append(current_period)\n",
    "        \n",
    "        # Sort by duration\n",
    "        inactive_periods.sort(key=lambda x: x['days'], reverse=True)\n",
    "        \n",
    "        print(f\"\\n  üö´ Longest inactive periods:\")\n",
    "        for i, period in enumerate(inactive_periods[:5]):  # Top 5 longest\n",
    "            print(f\"    {i+1}. {period['start']} to {period['end']} ({period['days']} days)\")\n",
    "        \n",
    "        # Check if fills data exists for active trading periods\n",
    "        if len(trading_days) > 0:\n",
    "            sample_dates = trading_days.head(10)\n",
    "            print(f\"\\n  üìÖ Checking fills data for sample trading days:\")\n",
    "            \n",
    "            for _, day in sample_dates.iterrows():\n",
    "                day_fills = acc_fills[acc_fills['datetime'].dt.date == day['date'].date()] if not acc_fills.empty else pd.DataFrame()\n",
    "                expected = int(day['fills'])\n",
    "                actual = len(day_fills)\n",
    "                status = \"‚úÖ\" if actual > 0 else \"‚ùå\"\n",
    "                print(f\"    {day['date'].strftime('%Y-%m-%d')}: Expected {expected} fills, Found {actual} {status}\")\n",
    "        \n",
    "        # Summary statistics\n",
    "        print(f\"\\n  üìà Summary Statistics:\")\n",
    "        print(f\"    Total expected fills: {acc_summary['fills'].sum():,}\")\n",
    "        print(f\"    Total actual fills: {len(acc_fills):,}\")\n",
    "        print(f\"    Fill capture rate: {len(acc_fills)/acc_summary['fills'].sum()*100:.1f}%\" if acc_summary['fills'].sum() > 0 else \"N/A\")\n",
    "        print(f\"    Last trading day: {trading_days['date'].max() if len(trading_days) > 0 else 'Never'}\")\n",
    "        print(f\"    Days since last trade: {(pd.Timestamp.now() - trading_days['date'].max()).days if len(trading_days) > 0 else 'N/A'}\")\n",
    "\n",
    "print(\"\\nüí° Insights:\")\n",
    "print(\"- Accounts may have summary data without fills during inactive periods\")\n",
    "print(\"- Fill data might be missing for certain date ranges\")\n",
    "print(\"- Some accounts may have stopped trading but still have daily summaries\")\n",
    "print(\"- Data download issues may have caused incomplete fills data\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (risk-tool)",
   "language": "python",
   "name": "risk-tool"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
