{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "ACCOUNT_ID = \"6973\"\n",
    "PATH_DIR = f\"../data/raw/totals_by_date/{ACCOUNT_ID}/\"\n",
    "\n",
    "\n",
    "def parse_multi_table_csv(path):\n",
    "    text = open(path, \"r\", encoding=\"utf-8\").read()\n",
    "    # Split into day blocks by lines starting with a date\n",
    "    day_blocks = re.split(r\"(?=^\\d{1,2}/\\d{1,2}/\\d{2,4})\", text, flags=re.MULTILINE)\n",
    "\n",
    "    result = {}\n",
    "    for block in day_blocks:\n",
    "        block = block.strip()\n",
    "        if not block:\n",
    "            continue\n",
    "\n",
    "        lines = block.splitlines()\n",
    "        date_str = lines[0].strip()\n",
    "        try:\n",
    "            date = pd.to_datetime(date_str).date()\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "        body = \"\\n\".join(lines[1:])\n",
    "\n",
    "        # --- HERE: split on any line that starts with \"Daily\" or \"Cash\"\n",
    "        sub_blocks = re.split(r\"(?=^(?:Fee|Daily|Cash))\", body, flags=re.MULTILINE)\n",
    "\n",
    "        for i, sub in enumerate(sub_blocks):\n",
    "            sub = sub.strip()\n",
    "            if not sub:\n",
    "                continue\n",
    "\n",
    "            sub_lines = sub.splitlines()\n",
    "            # first line is table name, e.g. \"Daily Interest\" or \"Cash Table\"\n",
    "\n",
    "            table_name = (\n",
    "                \"Orders\" if i == 0 else sub_lines[0].strip().replace(\" \", \"_\").lower()\n",
    "            )\n",
    "            csv_text = \"\\n\".join(sub_lines[(0 if i == 0 else 1) :])  # the header+rows\n",
    "\n",
    "            # parse into a DataFrame\n",
    "            df = pd.read_csv(StringIO(csv_text))\n",
    "\n",
    "            result[date] = df\n",
    "            break\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read all csv files in the directory and combine them into a single dataframe\n",
    "\n",
    "\n",
    "def read_csv_files_in_directory(directory):\n",
    "    path_pattern = os.path.join(directory, \"*.csv\")\n",
    "\n",
    "    # Get a list of all matching files\n",
    "    csv_files = glob.glob(path_pattern)\n",
    "    print(f\"Found {len(csv_files)} files.\")\n",
    "    df_list = []\n",
    "\n",
    "    for file in csv_files:\n",
    "        tables = parse_multi_table_csv(file)\n",
    "        for date, df in tables.items():\n",
    "            tmp = df.copy()  # don’t overwrite the original\n",
    "            tmp[\"date\"] = date  # add a new column\n",
    "            df_list.append(tmp)\n",
    "\n",
    "    # if df list is empty, return an empty DataFrame\n",
    "    if not df_list:\n",
    "        return pd.DataFrame()\n",
    "    # concatenate all DataFrames in the list into a single DataFrame\n",
    "    combined_df = pd.concat(df_list, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "totals_by_date = read_csv_files_in_directory(PATH_DIR)\n",
    "\n",
    "date_col = totals_by_date.pop(\"date\")\n",
    "totals_by_date.insert(0, \"date\", date_col)\n",
    "totals_by_date.sort_values(by=[\"date\"], inplace=True)\n",
    "totals_by_date.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_by_date.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fee_columns = [\n",
    "    \"Comm\",\n",
    "    \"Ecn Fee\",\n",
    "    \"SEC\",\n",
    "    \"ORF\",\n",
    "    \"CAT\",\n",
    "    \"TAF\",\n",
    "    \"FTT\",\n",
    "    \"NSCC\",\n",
    "    \"Acc\",\n",
    "    \"Clr\",\n",
    "    \"Misc\",\n",
    "]\n",
    "totals_by_date[\"fee_sum\"] = totals_by_date[fee_columns].sum(axis=1)\n",
    "totals_by_date.drop(fee_columns, axis=1, inplace=True)\n",
    "totals_by_date.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_map = {\n",
    "    \"Symbol\": \"symbol\",\n",
    "    \"Orders\": \"orders\",\n",
    "    \"Fills\": \"fills\",\n",
    "    \"Qty\": \"qty\",\n",
    "    \"Gross\": \"gross\",\n",
    "    \"Net\": \"net\",\n",
    "    \"Unrealized δ\": \"unrealized_delta\",\n",
    "    \"Total δ\": \"total_delta\",\n",
    "    \"Unrealized\": \"unrealized\",\n",
    "}\n",
    "totals_by_date.rename(mapper=rename_map, axis=1, inplace=True)\n",
    "totals_by_date[12:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    \"orders\",\n",
    "    \"fills\",\n",
    "    \"qty\",\n",
    "    \"gross\",\n",
    "    \"net\",\n",
    "    \"unrealized_delta\",\n",
    "    \"total_delta\",\n",
    "    \"unrealized\",\n",
    "    \"fee_sum\",\n",
    "]\n",
    "totals_by_date[numeric_cols] = totals_by_date[numeric_cols].apply(\n",
    "    pd.to_numeric, errors=\"coerce\"\n",
    ")\n",
    "totals_by_date[\"date\"] = pd.to_datetime(totals_by_date[\"date\"], format=\"%y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(totals_by_date.describe(include=\"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_by_date.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = (\n",
    "    totals_by_date.groupby(\"date\")\n",
    "    .agg(\n",
    "        symbols=(\"symbol\", \"nunique\"),\n",
    "        orders=(\"orders\", \"sum\"),\n",
    "        fills=(\"fills\", \"sum\"),\n",
    "        qty=(\"qty\", \"sum\"),\n",
    "        net=(\"net\", \"sum\"),\n",
    "        unrealized_delta=(\"unrealized_delta\", \"sum\"),\n",
    "        total_delta=(\"total_delta\", \"sum\"),\n",
    "        gross=(\"gross\", \"sum\"),\n",
    "        fee_sum=(\"fee_sum\", \"sum\"),\n",
    "    )\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling windows need a proper datetime index\n",
    "predictors = predictors.sort_index()\n",
    "\n",
    "# 3‑day rolling mean of total_delta\n",
    "predictors[\"td_3d_mean\"] = predictors[\"total_delta\"].rolling(3, min_periods=1).mean()\n",
    "\n",
    "# 5‑day rolling std (volatility)\n",
    "predictors[\"td_5d_std\"] = (\n",
    "    predictors[\"total_delta\"].rolling(5, min_periods=1).std().fillna(0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# start from your existing frame, indexed by date\n",
    "df = predictors.set_index(\"date\").sort_index()\n",
    "\n",
    "# 1.1 Rolling P/L history\n",
    "df[\"td_3d_mean\"] = df[\"total_delta\"].rolling(3, min_periods=1).mean()\n",
    "df[\"td_5d_std\"] = df[\"total_delta\"].rolling(5, min_periods=1).std().fillna(0)\n",
    "\n",
    "# 1.2 Fee impact\n",
    "# assume you also have a 'fee_sum' and 'gross' column\n",
    "df[\"fee_impact\"] = (df[\"fee_sum\"] / df[\"gross\"].replace(0, np.nan)).fillna(0)\n",
    "\n",
    "# 1.3 Time features\n",
    "df[\"dow\"] = df.index.dayofweek  # 0=Mon\n",
    "df[\"month\"] = df.index.month\n",
    "df[\"quarter\"] = df.index.quarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle(f\"../data/train/totals_by_date{ACCOUNT_ID}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
